---
title: "Visitor Survey Report: 2024 Season"
subtitle: "Ann Arbor Summer Festival [(A2SF)](https://www.a2sf.org/) at Top of the Park"
author: "Vicky Wang (viwa@umich.edu)"
output: html_document
---

```{r, results = "hide", echo=FALSE, warning= FALSE, message= FALSE}
library(dplyr)
library(zipcodeR)
library(usdata)
library(knitr)
library(ggplot2)
library(leaflet)
library(sf)
library(tidygeocoder)
library(lubridate)
library(tigris)
library(leaflet.extras)
library(htmlwidgets)
library(countries)
library(cities)
options(tigris_use_cache = TRUE, tigris_progress = FALSE)
```

```{r, echo=FALSE, warning= FALSE, message= FALSE}
in_season <- readxl::read_xlsx("In Season A2SF Survey data.xlsx")
post_season <- readxl::read_xlsx("Post Season A2SF Survey data.xlsx")
```

## Background/Overview

Two separate surveys were created, one for in-season participants, and one for post-season. In-season survey participants were recruited in-person at Top of the Park events by University of Michigan Community Technical Assistance Collaborative (CTAC) consultants between June 14-30th from ~5-10pm. Post-season participants were reached by email,[FILL MORE], Instagram. Both surveys were protected using CAPTCHA tests, but in-person responses were markedly less likely to be bot responses. This report contains:

* Cleaning and removal of potential bots from Post-Season survey results.

* Determination of best practices for data analysis

* Deep dive and results of zip codes - where are people from? 

* Compare and contrast ages, gender, ethnic background between the two surveys

* Break out “What are your favorite offerings tonight?” By night. How do we compare/combine the data from the two surveys. 

* Extrapolate age ranges for those who answered family offerings - who are they and can we reach out to them for more input?



### 1. Cleaning Post-Season Survey Data

*Remove non-US auto-collected countries and manual zip code entries that are not 5 characters.*

Rationale: Auto-collected countries outside of the United States is unlikely given the scope and target audience of the survey. Additional manual viewing row responses for non-US locations indicated bot behavior such as nonsensical free response answers. Zip code entries that are not 5 characters are unlikely, and few countries outside the US use postal codes.

First 6 Alphabetical Country-State Response Combinations
```{r, echo=FALSE, warning= FALSE, message= FALSE}
post_season_clean <- post_season %>%
  filter(nchar(`What is your zip code?`) == 5) %>%
  filter(`Country Code` == "US")

post_season_clean %>%
  select(`Country Code`,State,`What is your zip code?`) %>%
  group_by(`Country Code`, State) %>%
  summarise(`Number` = n()) %>%
  head() %>%
  kable()
```


*Determine bots using zip code and state collected data.*

Rationale: Because some United States responses are also bots, we have to be creative to identify more bots further. To do this, I use a function to identify states and zip codes and determine whether the zip codes, which respondents manually inputted, match with the states/countries, which was automatically collected from respondents' device locations.

```{r, echo=FALSE, warning= FALSE, message= FALSE}
post_season_clean$`What is your zip code?` <- as.character(post_season_clean$`What is your zip code?`)
# turns zip code column into character to be analyzed using zipR

is_bot <- function(zip, state) {
  # Handle potential NAs or invalid ZIPs
  if (is.na(zip) || nchar(zip) != 5 || !grepl("^[0-9]+$", zip)) {
    return(TRUE)  # If ZIP code is NA, not 5 characters, or not numeric
  }
  
  # Get state info from ZIP code
  zip_info <- zipcodeR::reverse_zipcode(zip)
  
  # Handle if the lookup fails
  if (is.null(zip_info) || nrow(zip_info) == 0) {
    return(TRUE)  # If ZIP code info is not found
  }
  state <- state2abbr(toupper(state))
  # Check if the provided state matches the ZIP code state
  zip_state <- zip_info$state
  return(zip_state != state)
}
#function to handle abnormal zip-state matchups, marking those not equal as FALSE

```

```{r, echo=FALSE, warning= FALSE, message= FALSE}
elim_bots <- post_season_clean %>%
  mutate(Bot = case_when(
    mapply(is_bot, `What is your zip code?`, State) ~ "Bot",
    TRUE ~ "Not Bot"
  )) %>%
  filter(Bot == "Not Bot")
# created new column that checks whether the zip code inputted and state auto-collected match and labeled seeming Bots accordingly. then filtered on "Not Bots"

elim_bots %>%
  select(`Respondent ID`, State, `Country Code`, Bot) %>%
  head() %>%
  kable()
```

*Determine unusually short duration survey response times.*

Rationale: Bots typically use short amounts of time to complete survey questions. 

```{r, echo=FALSE, warning= FALSE, message= FALSE}
elim_bots <- elim_bots %>%
  mutate(`Start Date` = as.POSIXct(`Start Date`, format = "%Y-%m-%d %H:%M:%S")) %>%
  mutate(EndDate = as.POSIXct(EndDate, format = "%Y-%m-%d %H:%M:%S")) %>%
  mutate(duration = difftime(EndDate, `Start Date`, units = "secs"))
# no duration is egregiously short to suggest bot presence
elim_bots %>%
  ggplot(aes(duration)) + geom_boxplot() + labs(title = "Survey Response Duration", x = "Duration (seconds)")
```

Takeaways: This boxplot indicates that no survey response was significantly shorter than the others. No bots were identified from this method.

*Manually identify any further responses as bots by examining free responses and determining whether any zip codes were "invalid" per this [link](https://www.unitedstateszipcodes.org/).*

Rationale: There is no straightforward method to determine further bots, as the remaining responses technically passed a variety of tests. Thus, the best practice is to manually analyze responses.

```{r, echo=FALSE, warning= FALSE, message= FALSE}
maybe_bots <- read.csv("manually_maybed.csv")
hopefully_notbot <- maybe_bots %>%
  filter(Bot == "Not Bot") # removed maybe bots for analysis

hopefully_notbot %>%
  select(Respondent.ID,State,What.is.your.zip.code.,Is.there.anything.else.you.would.like.to.share.about.Top.of.the.Park.or.A2SF.as.an.organization.) %>%
  head() %>%
  kable(col.names = c("Respondent ID", "State", "Zip Code", "Free Response"))
```

### 2. In-Season Survey Analysis

#### Where are visitors from?

*Understanding visitor origins by their manually collected zip codes.*

Rationale: non-5 digit zip codes were omitted, as it is difficult to determine the typing error committed to lead to an abnormal zip code. Additionally, collapsed all zip codes collected with count == 1 into an "Other" category in order to better visualize most common visitor homes.

```{r, echo=FALSE, warning= FALSE, message= FALSE}
is_count_zip <- in_season %>%
  group_by(`What is your zip code?`) %>%
  summarise(count = n()) %>%
  filter(nchar(`What is your zip code?`) == 5) %>%
  mutate(zip_group = case_when(
    count == 1 ~ "Other",
    TRUE ~ `What is your zip code?`
  ))

is_count_zip <- is_count_zip %>%
  group_by(zip_group, count) %>%
  summarise(count2 = n()) %>%
  ungroup() %>%
  mutate(combined = count*count2) %>%
  select(zip_group, combined)

is_count_zip <- is_count_zip %>%
  mutate(
    fraction = combined / sum(combined),
    ymax = cumsum(fraction),
    ymin = c(0, head(ymax, n = -1)),
    labelPosition = (ymax + ymin) / 2
    )

# Plot
ggplot(is_count_zip, aes(ymax = ymax, ymin = ymin, xmax = 4, xmin = 3, fill = zip_group)) +
  geom_rect(color="black") +
  geom_text(x = 4.2, aes(y = labelPosition, label = zip_group), size = 2) + # Position labels outside
  geom_segment(aes(x = 4, xend = 4, y = labelPosition, yend = labelPosition), color = "black") + # Add line from pie to label
  coord_polar(theta = "y") +
  ggtitle("Visitors by Zip Code") +
  scale_fill_brewer(palette = "PuRd") +
  theme_void() +
  theme(legend.position = "none")
```

*Secondary data visualization method, mapping visitor hometowns.*

Rationale: Pie charts fail to visually assess distance and neighborhood from which participants traveled. Mapping is used to determine density and distance. First, use geocode() to add latitude and longitudes to the dataframe based on their zip code.

```{r, echo=FALSE, warning= FALSE, message= FALSE}
is_zip_code_data <- zipcodeR::reverse_zipcode(in_season$`What is your zip code?`)

is_count_zip <- is_count_zip %>%
  left_join(is_zip_code_data, by = c('zip_group' = 'zipcode'))
```

```{r, echo=FALSE, warning= FALSE, message= FALSE}
counties_data <- counties(state = "MI", cb = TRUE)

cities_data <- places(state = "MI", cb = TRUE)

counties_michigan <- counties_data %>%
  st_transform(crs = 4326)

cities_michigan <- cities_data %>%
  st_transform(crs = 4326)

```


```{r, results="asis", echo=FALSE, warning= FALSE, message= FALSE}
leaflet() %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  setView(lng = -83.7597448169627, lat = 42.51812012808045, zoom = 9) %>%
  addPolygons(data = counties_michigan,
              weight = 1,
              color = "#1b7837",
              fill = TRUE,
              fillOpacity = 0.3,
              group = "Counties",
              highlightOptions = highlightOptions(
                weight = 3,
                color = "#66c2a5",
                fillOpacity = 0.4,
                bringToFront = FALSE
              ),
              label = ~NAME,
              labelOptions = labelOptions(
                style = list("font-weight" = "bold", padding = "3px 8px"),
                textsize = "13px",
                direction = "auto"
              )) %>%
  addPolygons(data = cities_michigan,
              weight = 1,
              color = "#225ea8",
              fill = TRUE,
              fillOpacity = 0.2,
              group = "Cities",
              highlightOptions = highlightOptions(
                weight = 3,
                color = "#8da0cb",
                fillOpacity = 0.3,
                bringToFront = FALSE
              ),
              label = ~NAME,
              labelOptions = labelOptions(
                style = list("font-weight" = "bold", padding = "3px 8px"),
                textsize = "13px",
                direction = "auto"
              )) %>%
  addCircleMarkers(
    data = is_count_zip,
    lat = ~lat,
    lng = ~lng,
    radius = ~sqrt(combined) * 2,  # Adjust the radius based on count
    color = "#A54767",
    fillColor = "#A54767",
    fillOpacity = 0.9,
    popup = ~paste("Zip Code:", zip_group, "<br/>", "Count:", combined, "<br/>", "Major City:", major_city, "<br/>", "County:", county)) %>%
  addLayersControl(
    overlayGroups = c("Counties", "Cities"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>%
  hideGroup(c("Counties", "Cities"))
```

*Visitors by home county.*

Although county data was not explicitly collected, we can extrapolate from zipcode data by using the zipcodeR package. This allows us to see zip code characteristics like population size, area in square miles, among other metadata.

```{r, echo=FALSE, warning= FALSE, message= FALSE}
county_count <- in_season %>%
  group_by(`What is your zip code?`) %>%
  summarise(count = n()) %>%
  filter(nchar(`What is your zip code?`) == 5) %>%
  mutate(zip_group = case_when(
    count == 1 ~ "Other",
    TRUE ~ `What is your zip code?`
  )) %>%
  group_by(zip_group, count) %>%
  summarise(count2 = n()) %>%
  ungroup() %>%
  mutate(combined = count*count2) %>%
  select(zip_group, combined) %>%
  left_join(is_zip_code_data, by = c('zip_group' = 'zipcode')) %>%
  group_by(county) %>%
  mutate(total_per_count = n()) %>%
  select(zip_group, combined, county, total_per_count)

county_count %>%
  group_by(county) %>%
  summarize(number = sum(combined)) %>%
  ggplot(aes(county, number, fill = county)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 20, vjust = 0.5, hjust = 0.5)) + scale_fill_brewer("PuRd") + theme(legend.position = "none") + labs(y = "Number of Visitors", x = "County", title = "Visitors by County (In-Season)")
```

#### What ages are visitors?

*Bar graph of number of visitors by their selected age group.*

Visitor ages are re-ordered in chronological form and labels are shortened to promote figure readability. A significantly high number of visitors were between the ages of 18-24. This may be due to a variety of reasons, including: (1) survey canvassers were in this approximate range, (2) younger adults have higher technological proficiency, among other explanations.

```{r, echo=FALSE, warning= FALSE, message= FALSE}
in_season$`What is your age?` <- factor(in_season$`What is your age?`, levels = c("Under 18 years", "18 to 24 years", "25 to 34 years", "35 to 44 years", "45 to 54 years", "55 to 64 years", "65 or older", "Decline to answer"))

new_labels <- c("Under 18", "18-24", "25-34", "35-44", "45-54", "55-64", "65+", "Declined")

in_season %>%
  group_by(`What is your age?`) %>%
  summarize(count = n()) %>%
  ggplot(aes(x = `What is your age?`, y = count, fill = `What is your age?`)) + 
  geom_bar(stat = "identity", position = position_dodge()) + geom_text(aes(label = count), vjust = 1.5, position = position_dodge(0.9), size = 2) +
  labs(x = "Age Group", y = "Count", title = "Number of Visitors by Age", fill = "Survey") +   theme(axis.text.x = element_text(angle = 45, hjust = 1)) + scale_x_discrete(labels = new_labels) + scale_fill_brewer("PuRd")
```
